{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SVt1SBAd7KU"
      },
      "source": [
        "# Text Classification using AutoTrain Advanced\n",
        "\n",
        "In this notebook, we will train a text classification model using AutoTrain Advanced.\n",
        "You can replace the model with any Hugging Face transformers compatible model and dataset with any other dataset in proper formatting.\n",
        "For dataset formatting, please take a look at [docs](https://huggingface.co/docs/autotrain/index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4tlm0qdd7KZ",
        "outputId": "2fb7307f-46d9-473b-8c8e-19c11bf3c679"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from autotrain.params import TextClassificationParams\n",
        "from autotrain.project import AutoTrainProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2X932mEMd7Kb"
      },
      "outputs": [],
      "source": [
        "HF_USERNAME = \"Lyreck\"\n",
        "HF_TOKEN = \"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\" # get it from https://huggingface.co/settings/token\n",
        "# It is recommended to use secrets or environment variables to store your HF_TOKEN\n",
        "# your token is required if push_to_hub is set to True or if you are accessing a gated model/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "gCVkD_yDd7Kc"
      },
      "outputs": [],
      "source": [
        "params = TextClassificationParams(\n",
        "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
        "    data_path=\"data/\", #\"Lyreck/tiktok_brat_comments\", # path to the dataset on huggingface hub\n",
        "    text_column=\"text\", # the column in the dataset that contains the text\n",
        "    target_column=\"label\", # the column in the dataset that contains the labels\n",
        "    train_split=\"train\",\n",
        "    valid_split=\"validation\",\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    max_seq_length=512,\n",
        "    lr=1e-5,\n",
        "    optimizer=\"adamw_torch\",\n",
        "    scheduler=\"linear\",\n",
        "    gradient_accumulation=1,\n",
        "    #mixed_precision=\"fp16\", #need graphic card for this (no mps available)\n",
        "    project_name=\"finetune-tiktok-brat3\",\n",
        "    log=\"tensorboard\",\n",
        "    push_to_hub=True,\n",
        "    username=HF_USERNAME,\n",
        "    token=HF_TOKEN,\n",
        ")\n",
        "# tip: you can use `?TextClassificationParams` to see the full list of allowed parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQxJU3w2d7Kc"
      },
      "source": [
        "If your dataset is in CSV / JSONL format (JSONL is most preferred) and is stored locally, make the following changes to `params`:\n",
        "\n",
        "```python\n",
        "params = TextClassificationParams(\n",
        "    data_path=\"data/\", # this is the path to folder where train.jsonl/train.csv is located\n",
        "    text_column=\"text\", # this is the column name in the CSV/JSONL file which contains the text\n",
        "    train_split = \"train\" # this is the filename without extension\n",
        "    valid_split = \"valid\" # this is the filename without extension\n",
        "    .\n",
        "    .\n",
        "    .\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTR4N3BSd7Kd",
        "outputId": "d535866f-18f6-4631-fe95-e417c828bd90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/preprocessor/text.py:108: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '2' '2' '2' '2' '2' '2' '2' '1' '2' '1' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[:, \"autotrain_label\"] = train_df[\"autotrain_label\"].astype(str)\n",
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/preprocessor/text.py:109: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '2' '2' '2' '2' '2' '1' '1' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  valid_df.loc[:, \"autotrain_label\"] = valid_df[\"autotrain_label\"].astype(str)\n",
            "Casting the dataset: 100%|██████████| 13/13 [00:00<00:00, 1311.00 examples/s]\n",
            "Casting the dataset: 100%|██████████| 10/10 [00:00<00:00, 1854.33 examples/s]\n",
            "Saving the dataset (1/1 shards): 100%|██████████| 13/13 [00:00<00:00, 764.74 examples/s] \n",
            "Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1343.77 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:26:16\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:26:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m523\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.text_classification', '--training_config', 'finetune-tiktok-brat3/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:26:16\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m524\u001b[0m - \u001b[1m{'data_path': 'finetune-tiktok-brat3/autotrain-data', 'model': 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'lr': 1e-05, 'epochs': 3, 'max_seq_length': 512, 'batch_size': 8, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'train_split': 'train', 'valid_split': 'validation', 'text_column': 'autotrain_text', 'target_column': 'autotrain_label', 'logging_steps': -1, 'project_name': 'finetune-tiktok-brat3', 'auto_find_batch_size': False, 'mixed_precision': None, 'save_total_limit': 1, 'token': '*****', 'push_to_hub': True, 'eval_strategy': 'epoch', 'username': 'Lyreck', 'log': 'tensorboard', 'early_stopping_patience': 5, 'early_stopping_threshold': 0.01}\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO     | 2024-11-08 23:26:40 | __main__:train:50 - loading dataset from disk\n",
            "INFO     | 2024-11-08 23:26:41 | __main__:train:70 - loading dataset from disk\n",
            "INFO     | 2024-11-08 23:26:47 | __main__:train:143 - Logging steps: 1\n",
            "INFO     | 2024-11-08 23:26:55 | autotrain.trainers.common:on_train_begin:386 - Starting to train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR    | 2024-11-08 23:26:59 | autotrain.trainers.common:wrapper:215 - train has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/trainers/common.py\", line 212, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/trainers/text_classification/__main__.py\", line 200, in train\n",
            "    trainer.train()\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 2123, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 2481, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 3579, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 3633, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 1327, in forward\n",
            "    outputs = self.roberta(\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 977, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 632, in forward\n",
            "    layer_outputs = layer_module(\n",
            "                    ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 521, in forward\n",
            "    self_attention_outputs = self.attention(\n",
            "                             ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 448, in forward\n",
            "    self_outputs = self.self(\n",
            "                   ^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 371, in forward\n",
            "    attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: MPS backend out of memory (MPS allocated: 5.69 GB, other allocations: 1.00 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
            "\n",
            "ERROR    | 2024-11-08 23:26:59 | autotrain.trainers.common:wrapper:216 - MPS backend out of memory (MPS allocated: 5.69 GB, other allocations: 1.00 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "22250"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this will train the model locally\n",
        "project = AutoTrainProject(params=params, backend=\"local\", process=True)\n",
        "project.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np_z8zWZECVL",
        "outputId": "d472f74d-d3d0-4ec6-bd96-dde7f71c3595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project.local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knEjOJ8qFpRe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.10 ('autotrainenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a22f54561fdef411d3f046bfb000304ae9de570ce055448268e2616c5911841"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
