{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SVt1SBAd7KU"
      },
      "source": [
        "# Text Classification using AutoTrain Advanced\n",
        "\n",
        "In this notebook, we will train a text classification model using AutoTrain Advanced.\n",
        "You can replace the model with any Hugging Face transformers compatible model and dataset with any other dataset in proper formatting.\n",
        "For dataset formatting, please take a look at [docs](https://huggingface.co/docs/autotrain/index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4tlm0qdd7KZ",
        "outputId": "2fb7307f-46d9-473b-8c8e-19c11bf3c679"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from autotrain.params import TextClassificationParams\n",
        "from autotrain.project import AutoTrainProject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2X932mEMd7Kb"
      },
      "outputs": [],
      "source": [
        "HF_USERNAME = \"Lyreck\"\n",
        "HF_TOKEN = \"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\" # get it from https://huggingface.co/settings/token\n",
        "# It is recommended to use secrets or environment variables to store your HF_TOKEN\n",
        "# your token is required if push_to_hub is set to True or if you are accessing a gated model/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gCVkD_yDd7Kc"
      },
      "outputs": [],
      "source": [
        "params = TextClassificationParams(\n",
        "    model=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
        "    data_path=\"data/\", #\"Lyreck/tiktok_brat_comments\", # path to the dataset on huggingface hub\n",
        "    text_column=\"text\", # the column in the dataset that contains the text\n",
        "    target_column=\"label\", # the column in the dataset that contains the labels\n",
        "    train_split=\"train\",\n",
        "    valid_split=\"validation\",\n",
        "    epochs=3,\n",
        "    batch_size=8,\n",
        "    max_seq_length=512,\n",
        "    lr=1e-5,\n",
        "    optimizer=\"adamw_torch\",\n",
        "    scheduler=\"linear\",\n",
        "    gradient_accumulation=1,\n",
        "    #mixed_precision=\"fp16\", #need graphic card for this (no mps available)\n",
        "    project_name=\"finetune-tiktok-brat2\",\n",
        "    log=\"tensorboard\",\n",
        "    push_to_hub=True,\n",
        "    username=HF_USERNAME,\n",
        "    token=HF_TOKEN,\n",
        ")\n",
        "# tip: you can use `?TextClassificationParams` to see the full list of allowed parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0;31mInit signature:\u001b[0m\n",
            "\u001b[0mTextClassificationParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mdata_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mwarmup_ratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mgradient_accumulation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adamw_torch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mscheduler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mweight_decay\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mtrain_split\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mvalid_split\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mtext_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mtarget_column\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mlogging_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mproject_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'project-name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mmixed_precision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0msave_total_limit\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mpush_to_hub\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0meval_strategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0musername\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mearly_stopping_patience\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m    \u001b[0mearly_stopping_threshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
            "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDocstring:\u001b[0m     \n",
            "[`TextClassificationParams`] is a configuration class for text classification training parameters.\n",
            "\n",
            "Attributes:\n",
            "    data_path (str): Path to the dataset.\n",
            "    model (str): Name of the model to use. Default is \"bert-base-uncased\".\n",
            "    lr (float): Learning rate. Default is 5e-5.\n",
            "    epochs (int): Number of training epochs. Default is 3.\n",
            "    max_seq_length (int): Maximum sequence length. Default is 128.\n",
            "    batch_size (int): Training batch size. Default is 8.\n",
            "    warmup_ratio (float): Warmup proportion. Default is 0.1.\n",
            "    gradient_accumulation (int): Number of gradient accumulation steps. Default is 1.\n",
            "    optimizer (str): Optimizer to use. Default is \"adamw_torch\".\n",
            "    scheduler (str): Scheduler to use. Default is \"linear\".\n",
            "    weight_decay (float): Weight decay. Default is 0.0.\n",
            "    max_grad_norm (float): Maximum gradient norm. Default is 1.0.\n",
            "    seed (int): Random seed. Default is 42.\n",
            "    train_split (str): Name of the training split. Default is \"train\".\n",
            "    valid_split (Optional[str]): Name of the validation split. Default is None.\n",
            "    text_column (str): Name of the text column in the dataset. Default is \"text\".\n",
            "    target_column (str): Name of the target column in the dataset. Default is \"target\".\n",
            "    logging_steps (int): Number of steps between logging. Default is -1.\n",
            "    project_name (str): Name of the project. Default is \"project-name\".\n",
            "    auto_find_batch_size (bool): Whether to automatically find the batch size. Default is False.\n",
            "    mixed_precision (Optional[str]): Mixed precision setting (fp16, bf16, or None). Default is None.\n",
            "    save_total_limit (int): Total number of checkpoints to save. Default is 1.\n",
            "    token (Optional[str]): Hub token for authentication. Default is None.\n",
            "    push_to_hub (bool): Whether to push the model to the hub. Default is False.\n",
            "    eval_strategy (str): Evaluation strategy. Default is \"epoch\".\n",
            "    username (Optional[str]): Hugging Face username. Default is None.\n",
            "    log (str): Logging method for experiment tracking. Default is \"none\".\n",
            "    early_stopping_patience (int): Number of epochs with no improvement after which training will be stopped. Default is 5.\n",
            "    early_stopping_threshold (float): Threshold for measuring the new optimum to continue training. Default is 0.01.\n",
            "\u001b[0;31mInit docstring:\u001b[0m Initialize the parameters, check for unused/extra parameters and warn the user.\n",
            "\u001b[0;31mFile:\u001b[0m           ~/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/trainers/text_classification/params.py\n",
            "\u001b[0;31mType:\u001b[0m           ModelMetaclass\n",
            "\u001b[0;31mSubclasses:\u001b[0m     "
          ]
        }
      ],
      "source": [
        "?TextClassificationParams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQxJU3w2d7Kc"
      },
      "source": [
        "If your dataset is in CSV / JSONL format (JSONL is most preferred) and is stored locally, make the following changes to `params`:\n",
        "\n",
        "```python\n",
        "params = TextClassificationParams(\n",
        "    data_path=\"data/\", # this is the path to folder where train.jsonl/train.csv is located\n",
        "    text_column=\"text\", # this is the column name in the CSV/JSONL file which contains the text\n",
        "    train_split = \"train\" # this is the filename without extension\n",
        "    valid_split = \"valid\" # this is the filename without extension\n",
        "    .\n",
        "    .\n",
        "    .\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTR4N3BSd7Kd",
        "outputId": "d535866f-18f6-4631-fe95-e417c828bd90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/preprocessor/text.py:108: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '2' '2' '2' '2' '2' '2' '2' '1' '2' '1' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  train_df.loc[:, \"autotrain_label\"] = train_df[\"autotrain_label\"].astype(str)\n",
            "/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/preprocessor/text.py:109: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['2' '2' '2' '2' '2' '2' '1' '1' '0' '0']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  valid_df.loc[:, \"autotrain_label\"] = valid_df[\"autotrain_label\"].astype(str)\n",
            "Casting the dataset: 100%|██████████| 13/13 [00:00<00:00, 2439.53 examples/s]\n",
            "Casting the dataset: 100%|██████████| 10/10 [00:00<00:00, 2565.32 examples/s]\n",
            "Saving the dataset (1/1 shards): 100%|██████████| 13/13 [00:00<00:00, 1915.14 examples/s]\n",
            "Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1875.81 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:14:23\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:14:23\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m523\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'no', '-m', 'autotrain.trainers.text_classification', '--training_config', 'finetune-tiktok-brat2/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-11-08 23:14:23\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m524\u001b[0m - \u001b[1m{'data_path': 'finetune-tiktok-brat2/autotrain-data', 'model': 'cardiffnlp/twitter-xlm-roberta-base-sentiment', 'lr': 1e-05, 'epochs': 3, 'max_seq_length': 512, 'batch_size': 8, 'warmup_ratio': 0.1, 'gradient_accumulation': 1, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.0, 'max_grad_norm': 1.0, 'seed': 42, 'train_split': 'train', 'valid_split': 'validation', 'text_column': 'autotrain_text', 'target_column': 'autotrain_label', 'logging_steps': -1, 'project_name': 'finetune-tiktok-brat2', 'auto_find_batch_size': False, 'mixed_precision': None, 'save_total_limit': 1, 'token': '*****', 'push_to_hub': True, 'eval_strategy': 'epoch', 'username': 'Lyreck', 'log': 'tensorboard', 'early_stopping_patience': 5, 'early_stopping_threshold': 0.01}\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO     | 2024-11-08 23:14:39 | __main__:train:50 - loading dataset from disk\n",
            "INFO     | 2024-11-08 23:14:39 | __main__:train:70 - loading dataset from disk\n",
            "INFO     | 2024-11-08 23:14:45 | __main__:train:143 - Logging steps: 1\n",
            "INFO     | 2024-11-08 23:14:50 | autotrain.trainers.common:on_train_begin:386 - Starting to train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ERROR    | 2024-11-08 23:14:54 | autotrain.trainers.common:wrapper:215 - train has failed due to an exception: Traceback (most recent call last):\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/trainers/common.py\", line 212, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/autotrain/trainers/text_classification/__main__.py\", line 200, in train\n",
            "    trainer.train()\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 2123, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 2481, in _inner_training_loop\n",
            "    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 3579, in training_step\n",
            "    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/trainer.py\", line 3633, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 1327, in forward\n",
            "    outputs = self.roberta(\n",
            "              ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 977, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "                      ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 632, in forward\n",
            "    layer_outputs = layer_module(\n",
            "                    ^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 521, in forward\n",
            "    self_attention_outputs = self.attention(\n",
            "                             ^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 448, in forward\n",
            "    self_outputs = self.self(\n",
            "                   ^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/leo/Desktop/Ecole/SciencesPo/S1/Socio_dig_pub_space/4_et_9-group_work/pythonneries/sociology_scrapping/tiktok_finetuning/autotrainenv/lib/python3.11/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 371, in forward\n",
            "    attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: MPS backend out of memory (MPS allocated: 5.69 GB, other allocations: 1.00 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n",
            "\n",
            "ERROR    | 2024-11-08 23:14:54 | autotrain.trainers.common:wrapper:216 - MPS backend out of memory (MPS allocated: 5.69 GB, other allocations: 1.00 GB, max allowed: 6.77 GB). Tried to allocate 96.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6 [00:03<?, ?it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "21596"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this will train the model locally\n",
        "project = AutoTrainProject(params=params, backend=\"local\", process=True)\n",
        "project.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np_z8zWZECVL",
        "outputId": "d472f74d-d3d0-4ec6-bd96-dde7f71c3595"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project.local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knEjOJ8qFpRe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.10 ('autotrainenv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a22f54561fdef411d3f046bfb000304ae9de570ce055448268e2616c5911841"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
